{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.400</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>53.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.968</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.368</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>328</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.344</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "600               1                     108              88              19   \n",
       "120               0                     162              76              56   \n",
       "508               2                      84              50              23   \n",
       "366               6                     124              72               0   \n",
       "480               3                     158              70              30   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "600        0  27.1              0.400   24             0  \n",
       "120      100  53.2              0.759   25             1  \n",
       "508       76  30.4              0.968   21             0  \n",
       "366        0  27.6              0.368   29             1  \n",
       "480      328  35.5              0.344   35             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.823\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 273us/step - loss: 0.8700 - accuracy: 0.3455 - val_loss: 0.8342 - val_accuracy: 0.3542\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.8461 - accuracy: 0.3507 - val_loss: 0.8130 - val_accuracy: 0.3646\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.8244 - accuracy: 0.3542 - val_loss: 0.7938 - val_accuracy: 0.3750\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.8047 - accuracy: 0.3611 - val_loss: 0.7765 - val_accuracy: 0.3854\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.7868 - accuracy: 0.3646 - val_loss: 0.7609 - val_accuracy: 0.4010\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.7707 - accuracy: 0.3767 - val_loss: 0.7469 - val_accuracy: 0.3958\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.7562 - accuracy: 0.3924 - val_loss: 0.7342 - val_accuracy: 0.4115\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.7430 - accuracy: 0.4132 - val_loss: 0.7228 - val_accuracy: 0.4323\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.7311 - accuracy: 0.4253 - val_loss: 0.7126 - val_accuracy: 0.4427\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.7203 - accuracy: 0.4462 - val_loss: 0.7034 - val_accuracy: 0.4688\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.7106 - accuracy: 0.4705 - val_loss: 0.6951 - val_accuracy: 0.5365\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.7019 - accuracy: 0.4913 - val_loss: 0.6877 - val_accuracy: 0.5521\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6940 - accuracy: 0.5174 - val_loss: 0.6810 - val_accuracy: 0.5521\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6869 - accuracy: 0.5399 - val_loss: 0.6750 - val_accuracy: 0.6042\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6804 - accuracy: 0.5503 - val_loss: 0.6696 - val_accuracy: 0.5729\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6746 - accuracy: 0.5677 - val_loss: 0.6647 - val_accuracy: 0.6042\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6693 - accuracy: 0.5903 - val_loss: 0.6603 - val_accuracy: 0.6146\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6645 - accuracy: 0.6163 - val_loss: 0.6563 - val_accuracy: 0.6198\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6601 - accuracy: 0.6285 - val_loss: 0.6528 - val_accuracy: 0.6354\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6561 - accuracy: 0.6458 - val_loss: 0.6495 - val_accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6525 - accuracy: 0.6372 - val_loss: 0.6466 - val_accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6492 - accuracy: 0.6597 - val_loss: 0.6439 - val_accuracy: 0.6719\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6462 - accuracy: 0.6632 - val_loss: 0.6415 - val_accuracy: 0.6719\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6435 - accuracy: 0.6649 - val_loss: 0.6393 - val_accuracy: 0.6823\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6409 - accuracy: 0.6736 - val_loss: 0.6373 - val_accuracy: 0.6927\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6387 - accuracy: 0.6736 - val_loss: 0.6355 - val_accuracy: 0.6875\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6365 - accuracy: 0.6823 - val_loss: 0.6338 - val_accuracy: 0.6875\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6345 - accuracy: 0.6858 - val_loss: 0.6322 - val_accuracy: 0.6875\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6328 - accuracy: 0.6840 - val_loss: 0.6308 - val_accuracy: 0.6875\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6311 - accuracy: 0.6892 - val_loss: 0.6295 - val_accuracy: 0.6875\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6295 - accuracy: 0.6892 - val_loss: 0.6283 - val_accuracy: 0.6875\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6281 - accuracy: 0.6892 - val_loss: 0.6272 - val_accuracy: 0.7031\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6267 - accuracy: 0.6875 - val_loss: 0.6261 - val_accuracy: 0.7031\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6255 - accuracy: 0.6910 - val_loss: 0.6251 - val_accuracy: 0.7083\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6243 - accuracy: 0.6840 - val_loss: 0.6242 - val_accuracy: 0.7031\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6232 - accuracy: 0.6823 - val_loss: 0.6234 - val_accuracy: 0.6979\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6221 - accuracy: 0.6840 - val_loss: 0.6226 - val_accuracy: 0.6979\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6211 - accuracy: 0.6840 - val_loss: 0.6218 - val_accuracy: 0.7031\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6202 - accuracy: 0.6840 - val_loss: 0.6211 - val_accuracy: 0.7031\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6193 - accuracy: 0.6823 - val_loss: 0.6204 - val_accuracy: 0.7031\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6185 - accuracy: 0.6823 - val_loss: 0.6197 - val_accuracy: 0.7031\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6176 - accuracy: 0.6806 - val_loss: 0.6191 - val_accuracy: 0.7031\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6169 - accuracy: 0.6771 - val_loss: 0.6185 - val_accuracy: 0.6979\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6161 - accuracy: 0.6771 - val_loss: 0.6179 - val_accuracy: 0.6927\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6154 - accuracy: 0.6771 - val_loss: 0.6173 - val_accuracy: 0.6927\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6147 - accuracy: 0.6771 - val_loss: 0.6168 - val_accuracy: 0.6875\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6141 - accuracy: 0.6771 - val_loss: 0.6163 - val_accuracy: 0.6875\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6134 - accuracy: 0.6771 - val_loss: 0.6157 - val_accuracy: 0.6875\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6128 - accuracy: 0.6788 - val_loss: 0.6152 - val_accuracy: 0.6875\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6122 - accuracy: 0.6788 - val_loss: 0.6148 - val_accuracy: 0.6927\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6116 - accuracy: 0.6788 - val_loss: 0.6143 - val_accuracy: 0.6927\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6110 - accuracy: 0.6788 - val_loss: 0.6138 - val_accuracy: 0.6927\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6105 - accuracy: 0.6771 - val_loss: 0.6133 - val_accuracy: 0.6927\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6099 - accuracy: 0.6771 - val_loss: 0.6129 - val_accuracy: 0.6927\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6094 - accuracy: 0.6771 - val_loss: 0.6124 - val_accuracy: 0.6927\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6088 - accuracy: 0.6753 - val_loss: 0.6120 - val_accuracy: 0.6927\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6083 - accuracy: 0.6736 - val_loss: 0.6116 - val_accuracy: 0.6927\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6078 - accuracy: 0.6736 - val_loss: 0.6111 - val_accuracy: 0.6927\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6073 - accuracy: 0.6736 - val_loss: 0.6107 - val_accuracy: 0.6927\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6068 - accuracy: 0.6736 - val_loss: 0.6103 - val_accuracy: 0.6927\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6063 - accuracy: 0.6736 - val_loss: 0.6099 - val_accuracy: 0.6927\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6058 - accuracy: 0.6736 - val_loss: 0.6094 - val_accuracy: 0.6927\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6053 - accuracy: 0.6736 - val_loss: 0.6090 - val_accuracy: 0.6927\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6049 - accuracy: 0.6753 - val_loss: 0.6086 - val_accuracy: 0.6927\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6044 - accuracy: 0.6753 - val_loss: 0.6082 - val_accuracy: 0.6927\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6039 - accuracy: 0.6753 - val_loss: 0.6078 - val_accuracy: 0.6927\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6035 - accuracy: 0.6753 - val_loss: 0.6074 - val_accuracy: 0.6927\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6030 - accuracy: 0.6753 - val_loss: 0.6070 - val_accuracy: 0.6979\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6025 - accuracy: 0.6753 - val_loss: 0.6066 - val_accuracy: 0.6979\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6021 - accuracy: 0.6753 - val_loss: 0.6062 - val_accuracy: 0.6979\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6016 - accuracy: 0.6753 - val_loss: 0.6058 - val_accuracy: 0.6979\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6012 - accuracy: 0.6753 - val_loss: 0.6054 - val_accuracy: 0.6979\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6008 - accuracy: 0.6771 - val_loss: 0.6050 - val_accuracy: 0.6979\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6003 - accuracy: 0.6771 - val_loss: 0.6046 - val_accuracy: 0.6979\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5999 - accuracy: 0.6771 - val_loss: 0.6042 - val_accuracy: 0.6979\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5995 - accuracy: 0.6771 - val_loss: 0.6038 - val_accuracy: 0.6979\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5990 - accuracy: 0.6771 - val_loss: 0.6034 - val_accuracy: 0.6979\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5986 - accuracy: 0.6771 - val_loss: 0.6030 - val_accuracy: 0.6979\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5982 - accuracy: 0.6771 - val_loss: 0.6026 - val_accuracy: 0.6979\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5977 - accuracy: 0.6788 - val_loss: 0.6022 - val_accuracy: 0.6979\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5973 - accuracy: 0.6788 - val_loss: 0.6018 - val_accuracy: 0.6979\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5969 - accuracy: 0.6788 - val_loss: 0.6014 - val_accuracy: 0.6979\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5965 - accuracy: 0.6788 - val_loss: 0.6010 - val_accuracy: 0.6979\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5960 - accuracy: 0.6788 - val_loss: 0.6006 - val_accuracy: 0.6979\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5956 - accuracy: 0.6788 - val_loss: 0.6002 - val_accuracy: 0.6979\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5952 - accuracy: 0.6788 - val_loss: 0.5999 - val_accuracy: 0.6979\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5948 - accuracy: 0.6788 - val_loss: 0.5995 - val_accuracy: 0.6979\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5944 - accuracy: 0.6788 - val_loss: 0.5991 - val_accuracy: 0.6979\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5940 - accuracy: 0.6788 - val_loss: 0.5987 - val_accuracy: 0.6979\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5936 - accuracy: 0.6788 - val_loss: 0.5983 - val_accuracy: 0.6979\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5931 - accuracy: 0.6788 - val_loss: 0.5979 - val_accuracy: 0.6979\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5927 - accuracy: 0.6788 - val_loss: 0.5975 - val_accuracy: 0.6979\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5923 - accuracy: 0.6788 - val_loss: 0.5972 - val_accuracy: 0.6979\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5919 - accuracy: 0.6788 - val_loss: 0.5968 - val_accuracy: 0.6979\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5915 - accuracy: 0.6788 - val_loss: 0.5964 - val_accuracy: 0.6979\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5911 - accuracy: 0.6806 - val_loss: 0.5960 - val_accuracy: 0.6979\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5907 - accuracy: 0.6840 - val_loss: 0.5956 - val_accuracy: 0.6979\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5903 - accuracy: 0.6840 - val_loss: 0.5953 - val_accuracy: 0.6979\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5899 - accuracy: 0.6840 - val_loss: 0.5949 - val_accuracy: 0.7031\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5895 - accuracy: 0.6840 - val_loss: 0.5945 - val_accuracy: 0.7031\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5891 - accuracy: 0.6840 - val_loss: 0.5941 - val_accuracy: 0.7083\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5887 - accuracy: 0.6840 - val_loss: 0.5937 - val_accuracy: 0.7083\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5883 - accuracy: 0.6840 - val_loss: 0.5934 - val_accuracy: 0.7083\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5879 - accuracy: 0.6840 - val_loss: 0.5930 - val_accuracy: 0.7083\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5875 - accuracy: 0.6840 - val_loss: 0.5926 - val_accuracy: 0.7083\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5871 - accuracy: 0.6840 - val_loss: 0.5922 - val_accuracy: 0.7083\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5867 - accuracy: 0.6840 - val_loss: 0.5919 - val_accuracy: 0.7083\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5864 - accuracy: 0.6840 - val_loss: 0.5915 - val_accuracy: 0.7083\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5860 - accuracy: 0.6840 - val_loss: 0.5911 - val_accuracy: 0.7083\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5856 - accuracy: 0.6840 - val_loss: 0.5908 - val_accuracy: 0.7083\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5852 - accuracy: 0.6840 - val_loss: 0.5904 - val_accuracy: 0.7083\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5848 - accuracy: 0.6858 - val_loss: 0.5900 - val_accuracy: 0.7083\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5844 - accuracy: 0.6858 - val_loss: 0.5897 - val_accuracy: 0.7083\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5840 - accuracy: 0.6875 - val_loss: 0.5893 - val_accuracy: 0.7083\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5837 - accuracy: 0.6875 - val_loss: 0.5889 - val_accuracy: 0.7083\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5832 - accuracy: 0.6892 - val_loss: 0.5886 - val_accuracy: 0.7083\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5829 - accuracy: 0.6892 - val_loss: 0.5882 - val_accuracy: 0.7083\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5825 - accuracy: 0.6892 - val_loss: 0.5878 - val_accuracy: 0.7083\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5821 - accuracy: 0.6892 - val_loss: 0.5875 - val_accuracy: 0.7083\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5817 - accuracy: 0.6875 - val_loss: 0.5871 - val_accuracy: 0.7083\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5814 - accuracy: 0.6875 - val_loss: 0.5867 - val_accuracy: 0.7083\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5810 - accuracy: 0.6875 - val_loss: 0.5864 - val_accuracy: 0.7083\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5806 - accuracy: 0.6892 - val_loss: 0.5860 - val_accuracy: 0.7083\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5802 - accuracy: 0.6910 - val_loss: 0.5857 - val_accuracy: 0.7083\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5798 - accuracy: 0.6910 - val_loss: 0.5853 - val_accuracy: 0.7083\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5795 - accuracy: 0.6927 - val_loss: 0.5849 - val_accuracy: 0.7083\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5791 - accuracy: 0.6944 - val_loss: 0.5846 - val_accuracy: 0.7135\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5787 - accuracy: 0.6927 - val_loss: 0.5842 - val_accuracy: 0.7135\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5783 - accuracy: 0.6944 - val_loss: 0.5839 - val_accuracy: 0.7135\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5780 - accuracy: 0.6944 - val_loss: 0.5835 - val_accuracy: 0.7135\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5776 - accuracy: 0.6944 - val_loss: 0.5832 - val_accuracy: 0.7135\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5772 - accuracy: 0.6962 - val_loss: 0.5828 - val_accuracy: 0.7135\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5768 - accuracy: 0.6962 - val_loss: 0.5825 - val_accuracy: 0.7135\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5765 - accuracy: 0.6962 - val_loss: 0.5821 - val_accuracy: 0.7135\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5761 - accuracy: 0.6979 - val_loss: 0.5818 - val_accuracy: 0.7135\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5758 - accuracy: 0.6979 - val_loss: 0.5814 - val_accuracy: 0.7135\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5754 - accuracy: 0.6997 - val_loss: 0.5811 - val_accuracy: 0.7135\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5750 - accuracy: 0.6979 - val_loss: 0.5807 - val_accuracy: 0.7135\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5746 - accuracy: 0.6979 - val_loss: 0.5804 - val_accuracy: 0.7135\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5743 - accuracy: 0.7014 - val_loss: 0.5800 - val_accuracy: 0.7188\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5739 - accuracy: 0.7014 - val_loss: 0.5797 - val_accuracy: 0.7188\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5736 - accuracy: 0.7031 - val_loss: 0.5793 - val_accuracy: 0.7188\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5732 - accuracy: 0.7031 - val_loss: 0.5790 - val_accuracy: 0.7188\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5729 - accuracy: 0.7049 - val_loss: 0.5786 - val_accuracy: 0.7188\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5725 - accuracy: 0.7066 - val_loss: 0.5783 - val_accuracy: 0.7188\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5721 - accuracy: 0.7066 - val_loss: 0.5780 - val_accuracy: 0.7188\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5718 - accuracy: 0.7066 - val_loss: 0.5776 - val_accuracy: 0.7188\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5714 - accuracy: 0.7066 - val_loss: 0.5773 - val_accuracy: 0.7188\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5711 - accuracy: 0.7049 - val_loss: 0.5769 - val_accuracy: 0.7188\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5707 - accuracy: 0.7066 - val_loss: 0.5766 - val_accuracy: 0.7135\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5704 - accuracy: 0.7083 - val_loss: 0.5763 - val_accuracy: 0.7135\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5700 - accuracy: 0.7083 - val_loss: 0.5759 - val_accuracy: 0.7188\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5697 - accuracy: 0.7083 - val_loss: 0.5756 - val_accuracy: 0.7188\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5693 - accuracy: 0.7083 - val_loss: 0.5753 - val_accuracy: 0.7188\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5689 - accuracy: 0.7083 - val_loss: 0.5749 - val_accuracy: 0.7188\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5686 - accuracy: 0.7083 - val_loss: 0.5746 - val_accuracy: 0.7188\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5683 - accuracy: 0.7101 - val_loss: 0.5743 - val_accuracy: 0.7188\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5679 - accuracy: 0.7101 - val_loss: 0.5739 - val_accuracy: 0.7188\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5676 - accuracy: 0.7083 - val_loss: 0.5736 - val_accuracy: 0.7188\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5672 - accuracy: 0.7066 - val_loss: 0.5733 - val_accuracy: 0.7240\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5668 - accuracy: 0.7066 - val_loss: 0.5730 - val_accuracy: 0.7240\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5665 - accuracy: 0.7066 - val_loss: 0.5726 - val_accuracy: 0.7240\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5662 - accuracy: 0.7083 - val_loss: 0.5723 - val_accuracy: 0.7240\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5658 - accuracy: 0.7101 - val_loss: 0.5720 - val_accuracy: 0.7240\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5655 - accuracy: 0.7101 - val_loss: 0.5716 - val_accuracy: 0.7240\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5652 - accuracy: 0.7101 - val_loss: 0.5713 - val_accuracy: 0.7240\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5648 - accuracy: 0.7118 - val_loss: 0.5710 - val_accuracy: 0.7240\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5645 - accuracy: 0.7118 - val_loss: 0.5707 - val_accuracy: 0.7240\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5641 - accuracy: 0.7118 - val_loss: 0.5704 - val_accuracy: 0.7240\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5638 - accuracy: 0.7135 - val_loss: 0.5700 - val_accuracy: 0.7240\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5634 - accuracy: 0.7153 - val_loss: 0.5697 - val_accuracy: 0.7240\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5631 - accuracy: 0.7135 - val_loss: 0.5694 - val_accuracy: 0.7240\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5628 - accuracy: 0.7153 - val_loss: 0.5691 - val_accuracy: 0.7240\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5624 - accuracy: 0.7153 - val_loss: 0.5688 - val_accuracy: 0.7240\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5621 - accuracy: 0.7153 - val_loss: 0.5685 - val_accuracy: 0.7292\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5618 - accuracy: 0.7135 - val_loss: 0.5681 - val_accuracy: 0.7396\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5614 - accuracy: 0.7135 - val_loss: 0.5678 - val_accuracy: 0.7396\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5611 - accuracy: 0.7135 - val_loss: 0.5675 - val_accuracy: 0.7396\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5608 - accuracy: 0.7118 - val_loss: 0.5672 - val_accuracy: 0.7396\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5604 - accuracy: 0.7135 - val_loss: 0.5669 - val_accuracy: 0.7396\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5601 - accuracy: 0.7118 - val_loss: 0.5666 - val_accuracy: 0.7396\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5598 - accuracy: 0.7118 - val_loss: 0.5663 - val_accuracy: 0.7396\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5594 - accuracy: 0.7118 - val_loss: 0.5660 - val_accuracy: 0.7396\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5591 - accuracy: 0.7118 - val_loss: 0.5656 - val_accuracy: 0.7396\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5588 - accuracy: 0.7135 - val_loss: 0.5653 - val_accuracy: 0.7396\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5585 - accuracy: 0.7101 - val_loss: 0.5650 - val_accuracy: 0.7396\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5581 - accuracy: 0.7118 - val_loss: 0.5647 - val_accuracy: 0.7396\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5578 - accuracy: 0.7118 - val_loss: 0.5644 - val_accuracy: 0.7396\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5575 - accuracy: 0.7118 - val_loss: 0.5641 - val_accuracy: 0.7396\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5572 - accuracy: 0.7118 - val_loss: 0.5638 - val_accuracy: 0.7396\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5568 - accuracy: 0.7118 - val_loss: 0.5635 - val_accuracy: 0.7396\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5565 - accuracy: 0.7118 - val_loss: 0.5632 - val_accuracy: 0.7344\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5562 - accuracy: 0.7118 - val_loss: 0.5629 - val_accuracy: 0.7344\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5559 - accuracy: 0.7118 - val_loss: 0.5626 - val_accuracy: 0.7292\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5556 - accuracy: 0.7118 - val_loss: 0.5623 - val_accuracy: 0.7292\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5553 - accuracy: 0.7118 - val_loss: 0.5620 - val_accuracy: 0.7292\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5549 - accuracy: 0.7118 - val_loss: 0.5617 - val_accuracy: 0.7292\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5546 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.7292\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5543 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.7292\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5540 - accuracy: 0.7135 - val_loss: 0.5608 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3865505 ],\n",
       "       [0.5151419 ],\n",
       "       [0.2967055 ],\n",
       "       [0.27065235],\n",
       "       [0.28071916],\n",
       "       [0.5127727 ],\n",
       "       [0.27497852],\n",
       "       [0.33881992],\n",
       "       [0.5379922 ],\n",
       "       [0.3170341 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.734\n",
      "roc-auc is 0.785\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14510cb4ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5537 - accuracy: 0.7153 - val_loss: 0.5605 - val_accuracy: 0.7344\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5534 - accuracy: 0.7153 - val_loss: 0.5602 - val_accuracy: 0.7344\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5531 - accuracy: 0.7170 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5528 - accuracy: 0.7188 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5524 - accuracy: 0.7153 - val_loss: 0.5594 - val_accuracy: 0.7344\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5521 - accuracy: 0.7153 - val_loss: 0.5591 - val_accuracy: 0.7344\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5518 - accuracy: 0.7135 - val_loss: 0.5588 - val_accuracy: 0.7344\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5515 - accuracy: 0.7153 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.5512 - accuracy: 0.7153 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5509 - accuracy: 0.7135 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5506 - accuracy: 0.7153 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5503 - accuracy: 0.7153 - val_loss: 0.5574 - val_accuracy: 0.7344\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5500 - accuracy: 0.7170 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5497 - accuracy: 0.7153 - val_loss: 0.5568 - val_accuracy: 0.7344\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5494 - accuracy: 0.7170 - val_loss: 0.5565 - val_accuracy: 0.7396\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5491 - accuracy: 0.7153 - val_loss: 0.5562 - val_accuracy: 0.7396\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5488 - accuracy: 0.7153 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5485 - accuracy: 0.7153 - val_loss: 0.5557 - val_accuracy: 0.7396\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5482 - accuracy: 0.7170 - val_loss: 0.5554 - val_accuracy: 0.7396\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5479 - accuracy: 0.7170 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5476 - accuracy: 0.7188 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5473 - accuracy: 0.7188 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5469 - accuracy: 0.7188 - val_loss: 0.5543 - val_accuracy: 0.7448\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5467 - accuracy: 0.7188 - val_loss: 0.5540 - val_accuracy: 0.7448\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5464 - accuracy: 0.7240 - val_loss: 0.5538 - val_accuracy: 0.7448\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5461 - accuracy: 0.7222 - val_loss: 0.5535 - val_accuracy: 0.7448\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5458 - accuracy: 0.7240 - val_loss: 0.5532 - val_accuracy: 0.7448\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5455 - accuracy: 0.7257 - val_loss: 0.5529 - val_accuracy: 0.7448\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5452 - accuracy: 0.7257 - val_loss: 0.5527 - val_accuracy: 0.7448\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5449 - accuracy: 0.7257 - val_loss: 0.5524 - val_accuracy: 0.7448\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5446 - accuracy: 0.7257 - val_loss: 0.5521 - val_accuracy: 0.7448\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5444 - accuracy: 0.7274 - val_loss: 0.5519 - val_accuracy: 0.7448\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5441 - accuracy: 0.7292 - val_loss: 0.5516 - val_accuracy: 0.7448\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5438 - accuracy: 0.7292 - val_loss: 0.5513 - val_accuracy: 0.7448\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5435 - accuracy: 0.7309 - val_loss: 0.5511 - val_accuracy: 0.7448\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5432 - accuracy: 0.7326 - val_loss: 0.5508 - val_accuracy: 0.7448\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5429 - accuracy: 0.7326 - val_loss: 0.5505 - val_accuracy: 0.7448\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5426 - accuracy: 0.7326 - val_loss: 0.5503 - val_accuracy: 0.7448\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5423 - accuracy: 0.7344 - val_loss: 0.5500 - val_accuracy: 0.7448\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5421 - accuracy: 0.7344 - val_loss: 0.5498 - val_accuracy: 0.7448\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5418 - accuracy: 0.7344 - val_loss: 0.5495 - val_accuracy: 0.7448\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5415 - accuracy: 0.7344 - val_loss: 0.5492 - val_accuracy: 0.7396\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5412 - accuracy: 0.7378 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5409 - accuracy: 0.7378 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5407 - accuracy: 0.7361 - val_loss: 0.5485 - val_accuracy: 0.7396\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5404 - accuracy: 0.7378 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5401 - accuracy: 0.7361 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5398 - accuracy: 0.7361 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5395 - accuracy: 0.7361 - val_loss: 0.5475 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5393 - accuracy: 0.7361 - val_loss: 0.5472 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.5390 - accuracy: 0.7361 - val_loss: 0.5469 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5387 - accuracy: 0.7396 - val_loss: 0.5467 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5385 - accuracy: 0.7396 - val_loss: 0.5464 - val_accuracy: 0.7604\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5382 - accuracy: 0.7378 - val_loss: 0.5462 - val_accuracy: 0.7604\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5379 - accuracy: 0.7378 - val_loss: 0.5460 - val_accuracy: 0.7604\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5376 - accuracy: 0.7396 - val_loss: 0.5457 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5374 - accuracy: 0.7396 - val_loss: 0.5455 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5371 - accuracy: 0.7396 - val_loss: 0.5452 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5368 - accuracy: 0.7413 - val_loss: 0.5450 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5365 - accuracy: 0.7413 - val_loss: 0.5447 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5363 - accuracy: 0.7413 - val_loss: 0.5445 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5360 - accuracy: 0.7413 - val_loss: 0.5442 - val_accuracy: 0.7604\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5357 - accuracy: 0.7413 - val_loss: 0.5440 - val_accuracy: 0.7604\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5355 - accuracy: 0.7413 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5352 - accuracy: 0.7413 - val_loss: 0.5435 - val_accuracy: 0.7604\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5350 - accuracy: 0.7413 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5347 - accuracy: 0.7413 - val_loss: 0.5430 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5344 - accuracy: 0.7413 - val_loss: 0.5428 - val_accuracy: 0.7604\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5342 - accuracy: 0.7413 - val_loss: 0.5426 - val_accuracy: 0.7604\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5339 - accuracy: 0.7413 - val_loss: 0.5423 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5337 - accuracy: 0.7413 - val_loss: 0.5421 - val_accuracy: 0.7604\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5334 - accuracy: 0.7413 - val_loss: 0.5419 - val_accuracy: 0.7604\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5331 - accuracy: 0.7413 - val_loss: 0.5416 - val_accuracy: 0.7604\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5329 - accuracy: 0.7413 - val_loss: 0.5414 - val_accuracy: 0.7604\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5326 - accuracy: 0.7413 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5324 - accuracy: 0.7413 - val_loss: 0.5409 - val_accuracy: 0.7656\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5321 - accuracy: 0.7431 - val_loss: 0.5407 - val_accuracy: 0.7656\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5319 - accuracy: 0.7431 - val_loss: 0.5405 - val_accuracy: 0.7656\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5316 - accuracy: 0.7431 - val_loss: 0.5403 - val_accuracy: 0.7656\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5314 - accuracy: 0.7431 - val_loss: 0.5400 - val_accuracy: 0.7656\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5311 - accuracy: 0.7431 - val_loss: 0.5398 - val_accuracy: 0.7656\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5309 - accuracy: 0.7431 - val_loss: 0.5396 - val_accuracy: 0.7656\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5306 - accuracy: 0.7431 - val_loss: 0.5394 - val_accuracy: 0.7656\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5304 - accuracy: 0.7431 - val_loss: 0.5391 - val_accuracy: 0.7656\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5301 - accuracy: 0.7431 - val_loss: 0.5389 - val_accuracy: 0.7656\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5299 - accuracy: 0.7431 - val_loss: 0.5387 - val_accuracy: 0.7656\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5296 - accuracy: 0.7431 - val_loss: 0.5385 - val_accuracy: 0.7656\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5294 - accuracy: 0.7431 - val_loss: 0.5382 - val_accuracy: 0.7656\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5291 - accuracy: 0.7431 - val_loss: 0.5380 - val_accuracy: 0.7656\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5289 - accuracy: 0.7413 - val_loss: 0.5378 - val_accuracy: 0.7656\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5286 - accuracy: 0.7413 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5284 - accuracy: 0.7413 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5282 - accuracy: 0.7396 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5279 - accuracy: 0.7413 - val_loss: 0.5369 - val_accuracy: 0.7656\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5277 - accuracy: 0.7431 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5274 - accuracy: 0.7431 - val_loss: 0.5365 - val_accuracy: 0.7708\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5272 - accuracy: 0.7431 - val_loss: 0.5363 - val_accuracy: 0.7760\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5269 - accuracy: 0.7431 - val_loss: 0.5361 - val_accuracy: 0.7708\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5267 - accuracy: 0.7431 - val_loss: 0.5359 - val_accuracy: 0.7708\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5265 - accuracy: 0.7431 - val_loss: 0.5357 - val_accuracy: 0.7708\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5262 - accuracy: 0.7431 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5260 - accuracy: 0.7448 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5258 - accuracy: 0.7448 - val_loss: 0.5350 - val_accuracy: 0.7656\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5255 - accuracy: 0.7448 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5253 - accuracy: 0.7448 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5251 - accuracy: 0.7465 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5248 - accuracy: 0.7465 - val_loss: 0.5342 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5246 - accuracy: 0.7500 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5244 - accuracy: 0.7500 - val_loss: 0.5338 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5241 - accuracy: 0.7500 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5239 - accuracy: 0.7500 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5237 - accuracy: 0.7500 - val_loss: 0.5332 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5235 - accuracy: 0.7517 - val_loss: 0.5330 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5232 - accuracy: 0.7517 - val_loss: 0.5328 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5230 - accuracy: 0.7517 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5227 - accuracy: 0.7517 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5225 - accuracy: 0.7517 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5223 - accuracy: 0.7517 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5221 - accuracy: 0.7517 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5219 - accuracy: 0.7517 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5216 - accuracy: 0.7517 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5214 - accuracy: 0.7517 - val_loss: 0.5312 - val_accuracy: 0.7656\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5212 - accuracy: 0.7517 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5210 - accuracy: 0.7517 - val_loss: 0.5308 - val_accuracy: 0.7656\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5208 - accuracy: 0.7517 - val_loss: 0.5306 - val_accuracy: 0.7656\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5205 - accuracy: 0.7517 - val_loss: 0.5304 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5203 - accuracy: 0.7500 - val_loss: 0.5302 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.5301 - val_accuracy: 0.7708\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5199 - accuracy: 0.7500 - val_loss: 0.5299 - val_accuracy: 0.7708\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5197 - accuracy: 0.7500 - val_loss: 0.5297 - val_accuracy: 0.7708\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5195 - accuracy: 0.7500 - val_loss: 0.5295 - val_accuracy: 0.7708\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5192 - accuracy: 0.7500 - val_loss: 0.5293 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5190 - accuracy: 0.7517 - val_loss: 0.5291 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5188 - accuracy: 0.7517 - val_loss: 0.5289 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5186 - accuracy: 0.7517 - val_loss: 0.5287 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5286 - val_accuracy: 0.7708\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5182 - accuracy: 0.7517 - val_loss: 0.5284 - val_accuracy: 0.7708\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5180 - accuracy: 0.7500 - val_loss: 0.5282 - val_accuracy: 0.7708\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5178 - accuracy: 0.7500 - val_loss: 0.5280 - val_accuracy: 0.7708\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5175 - accuracy: 0.7500 - val_loss: 0.5278 - val_accuracy: 0.7708\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.5277 - val_accuracy: 0.7708\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5171 - accuracy: 0.7500 - val_loss: 0.5275 - val_accuracy: 0.7708\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5169 - accuracy: 0.7500 - val_loss: 0.5273 - val_accuracy: 0.7708\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5167 - accuracy: 0.7500 - val_loss: 0.5271 - val_accuracy: 0.7708\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5165 - accuracy: 0.7500 - val_loss: 0.5269 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5163 - accuracy: 0.7500 - val_loss: 0.5268 - val_accuracy: 0.7708\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5161 - accuracy: 0.7500 - val_loss: 0.5266 - val_accuracy: 0.7708\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5159 - accuracy: 0.7500 - val_loss: 0.5264 - val_accuracy: 0.7708\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5157 - accuracy: 0.7500 - val_loss: 0.5262 - val_accuracy: 0.7708\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5155 - accuracy: 0.7500 - val_loss: 0.5261 - val_accuracy: 0.7708\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5153 - accuracy: 0.7500 - val_loss: 0.5259 - val_accuracy: 0.7708\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5151 - accuracy: 0.7500 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5149 - accuracy: 0.7500 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5147 - accuracy: 0.7500 - val_loss: 0.5254 - val_accuracy: 0.7708\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5145 - accuracy: 0.7500 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5143 - accuracy: 0.7500 - val_loss: 0.5250 - val_accuracy: 0.7708\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5141 - accuracy: 0.7517 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5139 - accuracy: 0.7535 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5137 - accuracy: 0.7535 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5135 - accuracy: 0.7535 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5133 - accuracy: 0.7535 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5131 - accuracy: 0.7535 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5129 - accuracy: 0.7535 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5127 - accuracy: 0.7535 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5125 - accuracy: 0.7535 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5123 - accuracy: 0.7535 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5122 - accuracy: 0.7517 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5119 - accuracy: 0.7552 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5117 - accuracy: 0.7552 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5116 - accuracy: 0.7552 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5114 - accuracy: 0.7552 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5112 - accuracy: 0.7552 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5110 - accuracy: 0.7552 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5108 - accuracy: 0.7552 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5106 - accuracy: 0.7552 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5104 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5103 - accuracy: 0.7569 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5101 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5099 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5097 - accuracy: 0.7604 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5095 - accuracy: 0.7604 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5094 - accuracy: 0.7604 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5092 - accuracy: 0.7604 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.65 - 0s 35us/step - loss: 0.5090 - accuracy: 0.7604 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5088 - accuracy: 0.7604 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5086 - accuracy: 0.7604 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5084 - accuracy: 0.7604 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5081 - accuracy: 0.7622 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5079 - accuracy: 0.7604 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5077 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5076 - accuracy: 0.7622 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5074 - accuracy: 0.7622 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5072 - accuracy: 0.7622 - val_loss: 0.5191 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5070 - accuracy: 0.7622 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5069 - accuracy: 0.7622 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5067 - accuracy: 0.7622 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5065 - accuracy: 0.7622 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5064 - accuracy: 0.7604 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5062 - accuracy: 0.7604 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.75 - 0s 49us/step - loss: 0.5060 - accuracy: 0.7604 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.5058 - accuracy: 0.7604 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5057 - accuracy: 0.7604 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5055 - accuracy: 0.7587 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5053 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5051 - accuracy: 0.7569 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5050 - accuracy: 0.7587 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5048 - accuracy: 0.7569 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5047 - accuracy: 0.7569 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5045 - accuracy: 0.7569 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5043 - accuracy: 0.7569 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5042 - accuracy: 0.7569 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5040 - accuracy: 0.7569 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5038 - accuracy: 0.7569 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5037 - accuracy: 0.7569 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.62 - 0s 40us/step - loss: 0.5035 - accuracy: 0.7569 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5032 - accuracy: 0.7569 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5030 - accuracy: 0.7569 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5029 - accuracy: 0.7569 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5027 - accuracy: 0.7569 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5025 - accuracy: 0.7569 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5024 - accuracy: 0.7569 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5022 - accuracy: 0.7569 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5021 - accuracy: 0.7587 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5019 - accuracy: 0.7587 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5018 - accuracy: 0.7569 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5016 - accuracy: 0.7587 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5014 - accuracy: 0.7587 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5013 - accuracy: 0.7587 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5011 - accuracy: 0.7587 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5010 - accuracy: 0.7587 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5009 - accuracy: 0.7587 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5007 - accuracy: 0.7604 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5005 - accuracy: 0.7604 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5004 - accuracy: 0.7604 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5002 - accuracy: 0.7604 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5001 - accuracy: 0.7604 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4999 - accuracy: 0.7604 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4998 - accuracy: 0.7604 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4996 - accuracy: 0.7622 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4995 - accuracy: 0.7622 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4993 - accuracy: 0.7622 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4992 - accuracy: 0.7622 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4990 - accuracy: 0.7622 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4989 - accuracy: 0.7622 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4987 - accuracy: 0.7622 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4986 - accuracy: 0.7622 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4984 - accuracy: 0.7622 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4983 - accuracy: 0.7622 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4982 - accuracy: 0.7622 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4980 - accuracy: 0.7622 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4979 - accuracy: 0.7622 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4977 - accuracy: 0.7622 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4976 - accuracy: 0.7622 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4975 - accuracy: 0.7622 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4973 - accuracy: 0.7622 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4972 - accuracy: 0.7622 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4970 - accuracy: 0.7622 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4969 - accuracy: 0.7622 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4968 - accuracy: 0.7622 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4966 - accuracy: 0.7622 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4965 - accuracy: 0.7639 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4963 - accuracy: 0.7639 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4962 - accuracy: 0.7639 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4960 - accuracy: 0.7639 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4958 - accuracy: 0.7639 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4957 - accuracy: 0.7639 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4955 - accuracy: 0.7639 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4954 - accuracy: 0.7639 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4953 - accuracy: 0.7639 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4951 - accuracy: 0.7639 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4950 - accuracy: 0.7639 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4949 - accuracy: 0.7639 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4947 - accuracy: 0.7639 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4946 - accuracy: 0.7639 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4945 - accuracy: 0.7639 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4943 - accuracy: 0.7639 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4942 - accuracy: 0.7639 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4941 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4940 - accuracy: 0.7639 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4938 - accuracy: 0.7639 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4937 - accuracy: 0.7639 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4936 - accuracy: 0.7639 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4934 - accuracy: 0.7639 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4933 - accuracy: 0.7639 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4932 - accuracy: 0.7639 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4931 - accuracy: 0.7639 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4928 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4927 - accuracy: 0.7639 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4926 - accuracy: 0.7639 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4925 - accuracy: 0.7639 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4923 - accuracy: 0.7639 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4922 - accuracy: 0.7639 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4919 - accuracy: 0.7639 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4918 - accuracy: 0.7639 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4917 - accuracy: 0.7639 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4916 - accuracy: 0.7639 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4915 - accuracy: 0.7639 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4913 - accuracy: 0.7639 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4912 - accuracy: 0.7639 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4911 - accuracy: 0.7639 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4910 - accuracy: 0.7639 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4907 - accuracy: 0.7639 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4906 - accuracy: 0.7639 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4905 - accuracy: 0.7639 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4903 - accuracy: 0.7656 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4901 - accuracy: 0.7656 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4900 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4898 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4897 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4896 - accuracy: 0.7656 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4895 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4894 - accuracy: 0.7656 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4893 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4892 - accuracy: 0.7656 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4890 - accuracy: 0.7656 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4888 - accuracy: 0.7674 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4887 - accuracy: 0.7674 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4884 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4883 - accuracy: 0.7674 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4882 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4880 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4880 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4878 - accuracy: 0.7674 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4878 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4876 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4874 - accuracy: 0.7674 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4873 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4872 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4871 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4870 - accuracy: 0.7674 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4869 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4868 - accuracy: 0.7674 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4867 - accuracy: 0.7674 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4866 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4865 - accuracy: 0.7674 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4864 - accuracy: 0.7674 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4863 - accuracy: 0.7674 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4862 - accuracy: 0.7674 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4859 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4858 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4856 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4855 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4853 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4852 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4851 - accuracy: 0.7674 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4850 - accuracy: 0.7674 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4849 - accuracy: 0.7674 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4848 - accuracy: 0.7674 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4847 - accuracy: 0.7674 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4846 - accuracy: 0.7674 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4845 - accuracy: 0.7674 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4843 - accuracy: 0.7674 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4842 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4840 - accuracy: 0.7674 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4839 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4837 - accuracy: 0.7674 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4836 - accuracy: 0.7674 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4835 - accuracy: 0.7674 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4829 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4828 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4827 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4827 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4826 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4825 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4824 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4823 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4806 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4805 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4803 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4803 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4801 - accuracy: 0.7708 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4800 - accuracy: 0.7708 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4800 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4799 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4798 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4797 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4795 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4795 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4794 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4793 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4791 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4789 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4782 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4778 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4775 - accuracy: 0.7708 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4773 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4771 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4769 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4764 - accuracy: 0.7691 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4762 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4737 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.71 - 0s 45us/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4733 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4731 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4731 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4730 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4730 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4729 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4728 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4728 - accuracy: 0.7708 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4727 - accuracy: 0.7708 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4726 - accuracy: 0.7708 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4726 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4724 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4723 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4723 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4722 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4717 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4715 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4715 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4710 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4710 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4705 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4705 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4703 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4703 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4689 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4689 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4688 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4688 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4678 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4678 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4662 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4662 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4661 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4661 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4660 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4660 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4657 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4657 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4656 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4656 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4656 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4655 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4655 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4655 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4655 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4654 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4654 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4654 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4653 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4653 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4653 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4651 - accuracy: 0.7674 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4651 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4651 - accuracy: 0.7674 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4651 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4650 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4650 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4650 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4649 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4649 - accuracy: 0.7656 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4649 - accuracy: 0.7656 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4649 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4648 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4648 - accuracy: 0.7656 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4647 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4647 - accuracy: 0.7674 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4647 - accuracy: 0.7639 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4645 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4645 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4645 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4644 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4644 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4644 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4644 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4643 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4643 - accuracy: 0.7656 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4643 - accuracy: 0.7656 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4643 - accuracy: 0.7656 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4642 - accuracy: 0.7656 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4642 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4642 - accuracy: 0.7656 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4642 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4641 - accuracy: 0.7656 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4641 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4641 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4640 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4640 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4640 - accuracy: 0.7674 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.68 - 0s 50us/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4635 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4635 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4635 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4634 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4634 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4634 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4634 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4634 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4633 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4633 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4633 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4633 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4631 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4631 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4631 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4631 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4630 - accuracy: 0.7674 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4618 - accuracy: 0.7708 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4617 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4612 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4612 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4612 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4612 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4610 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4610 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4610 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4610 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4610 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4608 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4608 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4608 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4608 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4608 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4607 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.71 - 0s 54us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14510d6c888>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 295us/step - loss: 0.6739 - accuracy: 0.5747 - val_loss: 0.6753 - val_accuracy: 0.5885\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6717 - accuracy: 0.5868 - val_loss: 0.6734 - val_accuracy: 0.6042\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6696 - accuracy: 0.5990 - val_loss: 0.6715 - val_accuracy: 0.6146\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6675 - accuracy: 0.6146 - val_loss: 0.6697 - val_accuracy: 0.6354\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6655 - accuracy: 0.6215 - val_loss: 0.6679 - val_accuracy: 0.6458\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6634 - accuracy: 0.6424 - val_loss: 0.6661 - val_accuracy: 0.6250\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6614 - accuracy: 0.6476 - val_loss: 0.6643 - val_accuracy: 0.6198\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6594 - accuracy: 0.6580 - val_loss: 0.6626 - val_accuracy: 0.6042\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6575 - accuracy: 0.6649 - val_loss: 0.6610 - val_accuracy: 0.6094\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6556 - accuracy: 0.6615 - val_loss: 0.6594 - val_accuracy: 0.6250\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6579 - val_accuracy: 0.6458\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6520 - accuracy: 0.6615 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6503 - accuracy: 0.6632 - val_loss: 0.6549 - val_accuracy: 0.6562\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6486 - accuracy: 0.6736 - val_loss: 0.6534 - val_accuracy: 0.6562\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6470 - accuracy: 0.6806 - val_loss: 0.6520 - val_accuracy: 0.6667\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6454 - accuracy: 0.6806 - val_loss: 0.6506 - val_accuracy: 0.6771\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.6438 - accuracy: 0.6910 - val_loss: 0.6493 - val_accuracy: 0.6823\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6423 - accuracy: 0.6840 - val_loss: 0.6480 - val_accuracy: 0.6667\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6409 - accuracy: 0.6806 - val_loss: 0.6467 - val_accuracy: 0.6615\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6394 - accuracy: 0.6771 - val_loss: 0.6454 - val_accuracy: 0.6719\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6380 - accuracy: 0.6875 - val_loss: 0.6442 - val_accuracy: 0.6719\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6366 - accuracy: 0.6840 - val_loss: 0.6430 - val_accuracy: 0.6875\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6352 - accuracy: 0.6858 - val_loss: 0.6418 - val_accuracy: 0.6927\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6339 - accuracy: 0.6840 - val_loss: 0.6407 - val_accuracy: 0.6927\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6327 - accuracy: 0.6840 - val_loss: 0.6396 - val_accuracy: 0.6979\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6314 - accuracy: 0.6823 - val_loss: 0.6385 - val_accuracy: 0.7031\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6301 - accuracy: 0.6840 - val_loss: 0.6374 - val_accuracy: 0.7031\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.6289 - accuracy: 0.6823 - val_loss: 0.6364 - val_accuracy: 0.7031\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6277 - accuracy: 0.6858 - val_loss: 0.6353 - val_accuracy: 0.6927\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6265 - accuracy: 0.6858 - val_loss: 0.6343 - val_accuracy: 0.6927\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6253 - accuracy: 0.6840 - val_loss: 0.6333 - val_accuracy: 0.6927\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6242 - accuracy: 0.6840 - val_loss: 0.6324 - val_accuracy: 0.6927\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.6231 - accuracy: 0.6840 - val_loss: 0.6314 - val_accuracy: 0.6875\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.6220 - accuracy: 0.6806 - val_loss: 0.6305 - val_accuracy: 0.6823\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6209 - accuracy: 0.6840 - val_loss: 0.6296 - val_accuracy: 0.6823\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6198 - accuracy: 0.6858 - val_loss: 0.6286 - val_accuracy: 0.6823\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6188 - accuracy: 0.6840 - val_loss: 0.6277 - val_accuracy: 0.6771\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6177 - accuracy: 0.6840 - val_loss: 0.6269 - val_accuracy: 0.6771\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6167 - accuracy: 0.6840 - val_loss: 0.6260 - val_accuracy: 0.6823\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6156 - accuracy: 0.6840 - val_loss: 0.6251 - val_accuracy: 0.6823\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6146 - accuracy: 0.6840 - val_loss: 0.6243 - val_accuracy: 0.6823\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6136 - accuracy: 0.6858 - val_loss: 0.6235 - val_accuracy: 0.6823\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6126 - accuracy: 0.6875 - val_loss: 0.6226 - val_accuracy: 0.6823\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6115 - accuracy: 0.6892 - val_loss: 0.6218 - val_accuracy: 0.6823\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6105 - accuracy: 0.6892 - val_loss: 0.6210 - val_accuracy: 0.6823\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6095 - accuracy: 0.6892 - val_loss: 0.6201 - val_accuracy: 0.6771\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6085 - accuracy: 0.6892 - val_loss: 0.6193 - val_accuracy: 0.6771\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6076 - accuracy: 0.6910 - val_loss: 0.6186 - val_accuracy: 0.6771\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6066 - accuracy: 0.6910 - val_loss: 0.6178 - val_accuracy: 0.6719\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6057 - accuracy: 0.6910 - val_loss: 0.6170 - val_accuracy: 0.6719\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6047 - accuracy: 0.6892 - val_loss: 0.6163 - val_accuracy: 0.6719\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6038 - accuracy: 0.6892 - val_loss: 0.6156 - val_accuracy: 0.6719\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6028 - accuracy: 0.6892 - val_loss: 0.6148 - val_accuracy: 0.6719\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6019 - accuracy: 0.6892 - val_loss: 0.6141 - val_accuracy: 0.6667\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6010 - accuracy: 0.6910 - val_loss: 0.6134 - val_accuracy: 0.6667\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6001 - accuracy: 0.6892 - val_loss: 0.6127 - val_accuracy: 0.6719\n",
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5992 - accuracy: 0.6910 - val_loss: 0.6120 - val_accuracy: 0.6719\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5983 - accuracy: 0.6910 - val_loss: 0.6113 - val_accuracy: 0.6719\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5974 - accuracy: 0.6927 - val_loss: 0.6106 - val_accuracy: 0.6719\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5966 - accuracy: 0.6927 - val_loss: 0.6099 - val_accuracy: 0.6719\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5957 - accuracy: 0.6927 - val_loss: 0.6092 - val_accuracy: 0.6667\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5948 - accuracy: 0.6927 - val_loss: 0.6086 - val_accuracy: 0.6667\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5940 - accuracy: 0.6927 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5931 - accuracy: 0.6927 - val_loss: 0.6072 - val_accuracy: 0.6667\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5922 - accuracy: 0.6927 - val_loss: 0.6066 - val_accuracy: 0.6667\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5913 - accuracy: 0.6910 - val_loss: 0.6059 - val_accuracy: 0.6667\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5904 - accuracy: 0.6927 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5895 - accuracy: 0.6927 - val_loss: 0.6047 - val_accuracy: 0.6719\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5886 - accuracy: 0.6927 - val_loss: 0.6040 - val_accuracy: 0.6719\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5877 - accuracy: 0.6910 - val_loss: 0.6034 - val_accuracy: 0.6719\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5868 - accuracy: 0.6910 - val_loss: 0.6027 - val_accuracy: 0.6719\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5859 - accuracy: 0.6910 - val_loss: 0.6021 - val_accuracy: 0.6719\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5849 - accuracy: 0.6910 - val_loss: 0.6014 - val_accuracy: 0.6719\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5840 - accuracy: 0.6910 - val_loss: 0.6008 - val_accuracy: 0.6719\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5831 - accuracy: 0.6892 - val_loss: 0.6001 - val_accuracy: 0.6719\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5822 - accuracy: 0.6910 - val_loss: 0.5994 - val_accuracy: 0.6719\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5813 - accuracy: 0.6910 - val_loss: 0.5988 - val_accuracy: 0.6719\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5804 - accuracy: 0.6910 - val_loss: 0.5981 - val_accuracy: 0.6719\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5795 - accuracy: 0.6910 - val_loss: 0.5975 - val_accuracy: 0.6719\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5787 - accuracy: 0.6910 - val_loss: 0.5969 - val_accuracy: 0.6719\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5778 - accuracy: 0.6927 - val_loss: 0.5963 - val_accuracy: 0.6719\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5769 - accuracy: 0.6927 - val_loss: 0.5956 - val_accuracy: 0.6719\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5760 - accuracy: 0.6927 - val_loss: 0.5950 - val_accuracy: 0.6667\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5752 - accuracy: 0.6927 - val_loss: 0.5944 - val_accuracy: 0.6667\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5743 - accuracy: 0.6944 - val_loss: 0.5937 - val_accuracy: 0.6667\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5734 - accuracy: 0.6944 - val_loss: 0.5931 - val_accuracy: 0.6667\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5725 - accuracy: 0.6962 - val_loss: 0.5925 - val_accuracy: 0.6667\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5716 - accuracy: 0.6962 - val_loss: 0.5918 - val_accuracy: 0.6667\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5708 - accuracy: 0.6962 - val_loss: 0.5912 - val_accuracy: 0.6667\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5699 - accuracy: 0.6997 - val_loss: 0.5906 - val_accuracy: 0.6667\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5690 - accuracy: 0.7014 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5681 - accuracy: 0.7031 - val_loss: 0.5893 - val_accuracy: 0.6667\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5673 - accuracy: 0.7031 - val_loss: 0.5886 - val_accuracy: 0.6667\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5664 - accuracy: 0.7031 - val_loss: 0.5880 - val_accuracy: 0.6667\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5655 - accuracy: 0.7031 - val_loss: 0.5874 - val_accuracy: 0.6667\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5647 - accuracy: 0.7014 - val_loss: 0.5867 - val_accuracy: 0.6667\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5638 - accuracy: 0.7014 - val_loss: 0.5861 - val_accuracy: 0.6667\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5629 - accuracy: 0.7014 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5621 - accuracy: 0.7031 - val_loss: 0.5849 - val_accuracy: 0.6667\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5612 - accuracy: 0.7031 - val_loss: 0.5842 - val_accuracy: 0.6667\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5604 - accuracy: 0.7031 - val_loss: 0.5836 - val_accuracy: 0.6667\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5595 - accuracy: 0.7031 - val_loss: 0.5830 - val_accuracy: 0.6667\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5587 - accuracy: 0.7031 - val_loss: 0.5824 - val_accuracy: 0.6667\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5578 - accuracy: 0.7031 - val_loss: 0.5818 - val_accuracy: 0.6667\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5569 - accuracy: 0.7031 - val_loss: 0.5811 - val_accuracy: 0.6667\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5560 - accuracy: 0.7031 - val_loss: 0.5805 - val_accuracy: 0.6667\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5552 - accuracy: 0.7049 - val_loss: 0.5799 - val_accuracy: 0.6719\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5543 - accuracy: 0.7049 - val_loss: 0.5793 - val_accuracy: 0.6771\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5534 - accuracy: 0.7049 - val_loss: 0.5787 - val_accuracy: 0.6771\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5525 - accuracy: 0.7049 - val_loss: 0.5781 - val_accuracy: 0.6771\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5516 - accuracy: 0.7066 - val_loss: 0.5775 - val_accuracy: 0.6771\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5508 - accuracy: 0.7083 - val_loss: 0.5769 - val_accuracy: 0.6771\n",
      "Epoch 113/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5499 - accuracy: 0.7083 - val_loss: 0.5764 - val_accuracy: 0.6771\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5490 - accuracy: 0.7101 - val_loss: 0.5758 - val_accuracy: 0.6771\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5482 - accuracy: 0.7101 - val_loss: 0.5752 - val_accuracy: 0.6771\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5473 - accuracy: 0.7101 - val_loss: 0.5747 - val_accuracy: 0.6875\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5465 - accuracy: 0.7101 - val_loss: 0.5741 - val_accuracy: 0.6927\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5456 - accuracy: 0.7101 - val_loss: 0.5736 - val_accuracy: 0.6927\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5448 - accuracy: 0.7101 - val_loss: 0.5730 - val_accuracy: 0.6927\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5439 - accuracy: 0.7101 - val_loss: 0.5725 - val_accuracy: 0.6875\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5431 - accuracy: 0.7118 - val_loss: 0.5719 - val_accuracy: 0.6875\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5422 - accuracy: 0.7118 - val_loss: 0.5713 - val_accuracy: 0.6875\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5413 - accuracy: 0.7135 - val_loss: 0.5708 - val_accuracy: 0.6875\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5404 - accuracy: 0.7135 - val_loss: 0.5702 - val_accuracy: 0.6875\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5396 - accuracy: 0.7170 - val_loss: 0.5697 - val_accuracy: 0.6875\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5387 - accuracy: 0.7170 - val_loss: 0.5691 - val_accuracy: 0.6927\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5379 - accuracy: 0.7188 - val_loss: 0.5686 - val_accuracy: 0.6927\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5370 - accuracy: 0.7188 - val_loss: 0.5680 - val_accuracy: 0.6927\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5361 - accuracy: 0.7188 - val_loss: 0.5675 - val_accuracy: 0.6927\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5352 - accuracy: 0.7188 - val_loss: 0.5669 - val_accuracy: 0.6927\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5343 - accuracy: 0.7205 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5334 - accuracy: 0.7188 - val_loss: 0.5659 - val_accuracy: 0.6875\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5325 - accuracy: 0.7257 - val_loss: 0.5653 - val_accuracy: 0.6875\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5316 - accuracy: 0.7240 - val_loss: 0.5648 - val_accuracy: 0.6875\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5306 - accuracy: 0.7240 - val_loss: 0.5642 - val_accuracy: 0.6927\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5297 - accuracy: 0.7257 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5288 - accuracy: 0.7274 - val_loss: 0.5632 - val_accuracy: 0.6927\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5279 - accuracy: 0.7274 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5269 - accuracy: 0.7274 - val_loss: 0.5621 - val_accuracy: 0.6927\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5260 - accuracy: 0.7292 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5251 - accuracy: 0.7292 - val_loss: 0.5611 - val_accuracy: 0.6979\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5242 - accuracy: 0.7309 - val_loss: 0.5606 - val_accuracy: 0.6979\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5233 - accuracy: 0.7326 - val_loss: 0.5601 - val_accuracy: 0.6979\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5225 - accuracy: 0.7344 - val_loss: 0.5597 - val_accuracy: 0.6927\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5216 - accuracy: 0.7344 - val_loss: 0.5592 - val_accuracy: 0.6927\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5207 - accuracy: 0.7361 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5199 - accuracy: 0.7378 - val_loss: 0.5582 - val_accuracy: 0.6927\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5190 - accuracy: 0.7396 - val_loss: 0.5577 - val_accuracy: 0.6979\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5181 - accuracy: 0.7396 - val_loss: 0.5572 - val_accuracy: 0.6927\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5172 - accuracy: 0.7431 - val_loss: 0.5567 - val_accuracy: 0.7031\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5162 - accuracy: 0.7431 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5153 - accuracy: 0.7465 - val_loss: 0.5558 - val_accuracy: 0.7135\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5144 - accuracy: 0.7500 - val_loss: 0.5553 - val_accuracy: 0.7135\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5135 - accuracy: 0.7465 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5544 - val_accuracy: 0.7135\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5117 - accuracy: 0.7483 - val_loss: 0.5540 - val_accuracy: 0.7135\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5109 - accuracy: 0.7465 - val_loss: 0.5536 - val_accuracy: 0.7135\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5100 - accuracy: 0.7517 - val_loss: 0.5531 - val_accuracy: 0.7135\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5091 - accuracy: 0.7500 - val_loss: 0.5527 - val_accuracy: 0.7135\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5082 - accuracy: 0.7500 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5074 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.7135\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5065 - accuracy: 0.7517 - val_loss: 0.5515 - val_accuracy: 0.7135\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5057 - accuracy: 0.7500 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5049 - accuracy: 0.7500 - val_loss: 0.5506 - val_accuracy: 0.7240\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5040 - accuracy: 0.7500 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5033 - accuracy: 0.7500 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5025 - accuracy: 0.7517 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5017 - accuracy: 0.7517 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5009 - accuracy: 0.7517 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5002 - accuracy: 0.7552 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4994 - accuracy: 0.7535 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4987 - accuracy: 0.7535 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4981 - accuracy: 0.7535 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4974 - accuracy: 0.7500 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4968 - accuracy: 0.7500 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4961 - accuracy: 0.7500 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4954 - accuracy: 0.7500 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4947 - accuracy: 0.7500 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4940 - accuracy: 0.7517 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4934 - accuracy: 0.7500 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4927 - accuracy: 0.7517 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4921 - accuracy: 0.7535 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4914 - accuracy: 0.7517 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4908 - accuracy: 0.7517 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4901 - accuracy: 0.7517 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4895 - accuracy: 0.7517 - val_loss: 0.5424 - val_accuracy: 0.7292\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4889 - accuracy: 0.7500 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4882 - accuracy: 0.7483 - val_loss: 0.5417 - val_accuracy: 0.7292\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4876 - accuracy: 0.7500 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4870 - accuracy: 0.7483 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4864 - accuracy: 0.7483 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4859 - accuracy: 0.7483 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4853 - accuracy: 0.7483 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4847 - accuracy: 0.7465 - val_loss: 0.5400 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4841 - accuracy: 0.7465 - val_loss: 0.5397 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4836 - accuracy: 0.7465 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4830 - accuracy: 0.7465 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4824 - accuracy: 0.7483 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4818 - accuracy: 0.7483 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4812 - accuracy: 0.7483 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4806 - accuracy: 0.7483 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4800 - accuracy: 0.7483 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4795 - accuracy: 0.7500 - val_loss: 0.5371 - val_accuracy: 0.7135\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4789 - accuracy: 0.7500 - val_loss: 0.5368 - val_accuracy: 0.7135\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4784 - accuracy: 0.7500 - val_loss: 0.5365 - val_accuracy: 0.7135\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4778 - accuracy: 0.7500 - val_loss: 0.5361 - val_accuracy: 0.7135\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4773 - accuracy: 0.7500 - val_loss: 0.5358 - val_accuracy: 0.7083\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4767 - accuracy: 0.7500 - val_loss: 0.5355 - val_accuracy: 0.7083\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4762 - accuracy: 0.7517 - val_loss: 0.5352 - val_accuracy: 0.7083\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4757 - accuracy: 0.7535 - val_loss: 0.5349 - val_accuracy: 0.7083\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4752 - accuracy: 0.7535 - val_loss: 0.5346 - val_accuracy: 0.7083\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4746 - accuracy: 0.7517 - val_loss: 0.5343 - val_accuracy: 0.7083\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4741 - accuracy: 0.7517 - val_loss: 0.5340 - val_accuracy: 0.7083\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4736 - accuracy: 0.7517 - val_loss: 0.5337 - val_accuracy: 0.7083\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4731 - accuracy: 0.7517 - val_loss: 0.5334 - val_accuracy: 0.7083\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4726 - accuracy: 0.7552 - val_loss: 0.5331 - val_accuracy: 0.7083\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4721 - accuracy: 0.7552 - val_loss: 0.5329 - val_accuracy: 0.7083\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4716 - accuracy: 0.7552 - val_loss: 0.5326 - val_accuracy: 0.7083\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4712 - accuracy: 0.7569 - val_loss: 0.5323 - val_accuracy: 0.7083\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4707 - accuracy: 0.7569 - val_loss: 0.5321 - val_accuracy: 0.7083\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4703 - accuracy: 0.7587 - val_loss: 0.5318 - val_accuracy: 0.7135\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4698 - accuracy: 0.7587 - val_loss: 0.5316 - val_accuracy: 0.7135\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4694 - accuracy: 0.7604 - val_loss: 0.5314 - val_accuracy: 0.7135\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4689 - accuracy: 0.7622 - val_loss: 0.5312 - val_accuracy: 0.7135\n",
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5309 - val_accuracy: 0.7135\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4681 - accuracy: 0.7622 - val_loss: 0.5307 - val_accuracy: 0.7135\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4678 - accuracy: 0.7622 - val_loss: 0.5305 - val_accuracy: 0.7135\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4674 - accuracy: 0.7622 - val_loss: 0.5303 - val_accuracy: 0.7135\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4670 - accuracy: 0.7622 - val_loss: 0.5301 - val_accuracy: 0.7135\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4666 - accuracy: 0.7604 - val_loss: 0.5299 - val_accuracy: 0.7135\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4663 - accuracy: 0.7622 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4659 - accuracy: 0.7604 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4655 - accuracy: 0.7604 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4652 - accuracy: 0.7604 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4649 - accuracy: 0.7604 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4646 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4642 - accuracy: 0.7604 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4639 - accuracy: 0.7587 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4636 - accuracy: 0.7587 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4633 - accuracy: 0.7604 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4630 - accuracy: 0.7587 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4627 - accuracy: 0.7569 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4624 - accuracy: 0.7569 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4621 - accuracy: 0.7587 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4619 - accuracy: 0.7587 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4616 - accuracy: 0.7587 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4614 - accuracy: 0.7587 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4611 - accuracy: 0.7587 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4608 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4606 - accuracy: 0.7587 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4603 - accuracy: 0.7587 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4601 - accuracy: 0.7587 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4598 - accuracy: 0.7587 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4596 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4593 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4591 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4589 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4586 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4583 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4581 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4579 - accuracy: 0.7604 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4576 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4574 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4572 - accuracy: 0.7604 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4569 - accuracy: 0.7587 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4567 - accuracy: 0.7569 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4565 - accuracy: 0.7587 - val_loss: 0.5254 - val_accuracy: 0.7240\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4562 - accuracy: 0.7569 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4560 - accuracy: 0.7587 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4558 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7188\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4556 - accuracy: 0.7604 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4553 - accuracy: 0.7604 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4551 - accuracy: 0.7622 - val_loss: 0.5249 - val_accuracy: 0.7135\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4549 - accuracy: 0.7622 - val_loss: 0.5248 - val_accuracy: 0.7135\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4547 - accuracy: 0.7639 - val_loss: 0.5247 - val_accuracy: 0.7135\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4545 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4542 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4540 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4538 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4536 - accuracy: 0.7622 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4534 - accuracy: 0.7604 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4532 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4530 - accuracy: 0.7639 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4528 - accuracy: 0.7622 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4526 - accuracy: 0.7604 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4524 - accuracy: 0.7639 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4522 - accuracy: 0.7622 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4520 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4518 - accuracy: 0.7622 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4516 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4515 - accuracy: 0.7604 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4513 - accuracy: 0.7622 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4511 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4509 - accuracy: 0.7656 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4507 - accuracy: 0.7604 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4506 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7240\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4504 - accuracy: 0.7604 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4502 - accuracy: 0.7587 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4501 - accuracy: 0.7604 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4499 - accuracy: 0.7587 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4497 - accuracy: 0.7604 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4496 - accuracy: 0.7639 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4494 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4492 - accuracy: 0.7639 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4491 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4489 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4488 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4486 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4484 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4483 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4482 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4480 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4479 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4477 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4476 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4475 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4474 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4470 - accuracy: 0.7708 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4468 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4459 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4458 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4457 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4454 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4453 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4446 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4443 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.65 - 0s 35us/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4434 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4431 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4428 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4425 - accuracy: 0.7743 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4424 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4418 - accuracy: 0.7795 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.75 - 0s 35us/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.81 - 0s 33us/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4388 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.81 - 0s 35us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.81 - 0s 35us/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.90 - 0s 33us/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.78 - 0s 33us/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.81 - 0s 35us/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.68 - 0s 35us/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4332 - accuracy: 0.7778 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.75 - 0s 33us/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4331 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.75 - 0s 35us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4325 - accuracy: 0.7778 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4322 - accuracy: 0.7778 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7778 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4310 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.75 - 0s 36us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.75 - 0s 35us/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.90 - 0s 35us/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.75 - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.75 - 0s 35us/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.75 - 0s 35us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.71 - 0s 35us/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4250 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4247 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.81 - 0s 35us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7865 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4240 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4240 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.7830 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.7847 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7830 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7830 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7847 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7847 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4232 - accuracy: 0.7847 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4231 - accuracy: 0.7847 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4230 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.7847 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4227 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4228 - accuracy: 0.7830 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4227 - accuracy: 0.7847 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4226 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4226 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4223 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7847 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7847 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.71 - 0s 38us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4216 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.90 - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4215 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7830 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4213 - accuracy: 0.7830 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7830 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4209 - accuracy: 0.7847 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.71 - 0s 35us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4207 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7865 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.75 - 0s 35us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.87 - 0s 33us/step - loss: 0.4206 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7812 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7812 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7812 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4201 - accuracy: 0.7812 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7812 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7812 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7812 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7812 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4198 - accuracy: 0.7812 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.78 - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.81 - 0s 38us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4193 - accuracy: 0.7830 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.87 - 0s 33us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.84 - 0s 35us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7830 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4189 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7830 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7812 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7830 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7830 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4183 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4184 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7830 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4182 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.71 - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.81 - 0s 43us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.7865 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4179 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4177 - accuracy: 0.7812 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4175 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7795 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4174 - accuracy: 0.7778 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7795 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4170 - accuracy: 0.7812 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4171 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7812 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - accuracy: 0.7830 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4149 - accuracy: 0.7830 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4149 - accuracy: 0.7830 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7830 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7830 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7830 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7830 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4142 - accuracy: 0.7847 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4142 - accuracy: 0.7830 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4142 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.729\n",
      "roc-auc is 0.796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
